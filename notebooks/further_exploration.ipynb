{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Inspecting and Exploring Recommendations for Specific Titles\n",
    "\n",
    "In this notebook, we'll delve into the performance of our recommendation system by focusing on three specific titles:\n",
    "\n",
    "- **tm107473**: *Morning Glory*\n",
    "- **tm50355**: *The Right Stuff*\n",
    "- **ts89259**: *The Queen's Gambit*\n",
    "\n",
    "Our objectives are to:\n",
    "\n",
    "1. **Identify** users who interacted with these titles and have at least one additional interaction afterward.\n",
    "2. **Define** what ideal recommendations should look like based on these interactions.\n",
    "3. **Compare** these ideal recommendations with those generated by our current weighted recommender.\n",
    "4. **Determine** the optimal value of `k` to improve recommendation quality.\n"
   ],
   "id": "4bece28fa4be3b4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T18:45:37.187727Z",
     "start_time": "2024-10-15T18:45:37.183918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Reader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options for better readability\n",
    "pd.set_option('display.max_columns', None)\n"
   ],
   "id": "c0cf4fd4172f434a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Loading Processed Data\n",
    "\n",
    "We'll begin by loading the preprocessed `titles` and `interactions` datasets.\n"
   ],
   "id": "435c0b2f4cb2391d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T18:45:53.331692Z",
     "start_time": "2024-10-15T18:45:42.057367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "PROCESSED_TITLES_PATH = 'titles.csv.gz'\n",
    "PROCESSED_INTERACTIONS_PATH = 'interactions_cleaned.csv' \n",
    "\n",
    "# Load the data\n",
    "titles_df = pd.read_csv(PROCESSED_TITLES_PATH)\n",
    "interactions_df = pd.read_csv(PROCESSED_INTERACTIONS_PATH)\n",
    "\n",
    "# Display the first few rows of each DataFrame\n",
    "print(\"Titles DataFrame:\")\n",
    "display(titles_df.head())\n",
    "\n",
    "print(\"\\nInteractions DataFrame:\")\n",
    "display(interactions_df.head())\n"
   ],
   "id": "de60526baa1cc4aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "    TITLE_ID           ORIGINAL_TITLE ORIGINAL_LANGUAGE  \\\n",
       "0  tm1282307  L'ultima notte di Amore                it   \n",
       "1  tm1338500       Bird Box Barcelona                es   \n",
       "2   ts371824        Steeltown Murders                en   \n",
       "3   tm123363              Expend4bles                en   \n",
       "4  tm1045025                       65                en   \n",
       "\n",
       "   RELEASE_DURATION_DAYS                                         GENRE_TMDB  \\\n",
       "0                    484                     [\\n  \"drama\",\\n  \"thriller\"\\n]   \n",
       "1                    357        [\\n  \"horror\",\\n  \"scifi\",\\n  \"thriller\"\\n]   \n",
       "2                    417  [\\n  \"crime\",\\n  \"drama\",\\n  \"history\",\\n  \"th...   \n",
       "3                    294          [\\n  \"action\",\\n  \"thriller\",\\n  \"war\"\\n]   \n",
       "4                    491  [\\n  \"action\",\\n  \"drama\",\\n  \"scifi\",\\n  \"thr...   \n",
       "\n",
       "                                   DIRECTOR  \\\n",
       "0               [\\n  \"Andrea Di Stefano\"\\n]   \n",
       "1  [\\n  \"David Pastor\",\\n  \"Àlex Pastor\"\\n]   \n",
       "2                      [\\n  \"Marc Evans\"\\n]   \n",
       "3                     [\\n  \"Scott Waugh\"\\n]   \n",
       "4    [\\n  \"Bryan Woods\",\\n  \"Scott Beck\"\\n]   \n",
       "\n",
       "                                               ACTOR  \\\n",
       "0  [\\n  \"Pierfrancesco Favino\",\\n  \"Linda Caridi\"...   \n",
       "1  [\\n  \"Mario Casas\",\\n  \"Georgina Campbell\",\\n ...   \n",
       "2  [\\n  \"Scott Arthur\",\\n  \"Sion Alun Davies\",\\n ...   \n",
       "3  [\\n  \"Jason Statham\",\\n  \"Sylvester Stallone\",...   \n",
       "4  [\\n  \"Adam Driver\",\\n  \"Ariana Greenblatt\",\\n ...   \n",
       "\n",
       "                                            PRODUCER  \\\n",
       "0  [\\n  \"Benedetto Habib\",\\n  \"Daniel Campos Pavo...   \n",
       "1  [\\n  \"Adrián Guerra\",\\n  \"Chris Morgan\",\\n  \"D...   \n",
       "2                            [\\n  \"Hannah Thomas\"\\n]   \n",
       "3  [\\n  \"Jason Statham\",\\n  \"Jeffrey Greenstein\",...   \n",
       "4  [\\n  \"Bryan Woods\",\\n  \"Deborah Liebling\",\\n  ...   \n",
       "\n",
       "                                     WRITER  \n",
       "0                                       NaN  \n",
       "1  [\\n  \"David Pastor\",\\n  \"Àlex Pastor\"\\n]  \n",
       "2                     [\\n  \"Ed Whitmore\"\\n]  \n",
       "3                                       NaN  \n",
       "4    [\\n  \"Bryan Woods\",\\n  \"Scott Beck\"\\n]  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_ID</th>\n",
       "      <th>ORIGINAL_TITLE</th>\n",
       "      <th>ORIGINAL_LANGUAGE</th>\n",
       "      <th>RELEASE_DURATION_DAYS</th>\n",
       "      <th>GENRE_TMDB</th>\n",
       "      <th>DIRECTOR</th>\n",
       "      <th>ACTOR</th>\n",
       "      <th>PRODUCER</th>\n",
       "      <th>WRITER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm1282307</td>\n",
       "      <td>L'ultima notte di Amore</td>\n",
       "      <td>it</td>\n",
       "      <td>484</td>\n",
       "      <td>[\\n  \"drama\",\\n  \"thriller\"\\n]</td>\n",
       "      <td>[\\n  \"Andrea Di Stefano\"\\n]</td>\n",
       "      <td>[\\n  \"Pierfrancesco Favino\",\\n  \"Linda Caridi\"...</td>\n",
       "      <td>[\\n  \"Benedetto Habib\",\\n  \"Daniel Campos Pavo...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm1338500</td>\n",
       "      <td>Bird Box Barcelona</td>\n",
       "      <td>es</td>\n",
       "      <td>357</td>\n",
       "      <td>[\\n  \"horror\",\\n  \"scifi\",\\n  \"thriller\"\\n]</td>\n",
       "      <td>[\\n  \"David Pastor\",\\n  \"Àlex Pastor\"\\n]</td>\n",
       "      <td>[\\n  \"Mario Casas\",\\n  \"Georgina Campbell\",\\n ...</td>\n",
       "      <td>[\\n  \"Adrián Guerra\",\\n  \"Chris Morgan\",\\n  \"D...</td>\n",
       "      <td>[\\n  \"David Pastor\",\\n  \"Àlex Pastor\"\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ts371824</td>\n",
       "      <td>Steeltown Murders</td>\n",
       "      <td>en</td>\n",
       "      <td>417</td>\n",
       "      <td>[\\n  \"crime\",\\n  \"drama\",\\n  \"history\",\\n  \"th...</td>\n",
       "      <td>[\\n  \"Marc Evans\"\\n]</td>\n",
       "      <td>[\\n  \"Scott Arthur\",\\n  \"Sion Alun Davies\",\\n ...</td>\n",
       "      <td>[\\n  \"Hannah Thomas\"\\n]</td>\n",
       "      <td>[\\n  \"Ed Whitmore\"\\n]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm123363</td>\n",
       "      <td>Expend4bles</td>\n",
       "      <td>en</td>\n",
       "      <td>294</td>\n",
       "      <td>[\\n  \"action\",\\n  \"thriller\",\\n  \"war\"\\n]</td>\n",
       "      <td>[\\n  \"Scott Waugh\"\\n]</td>\n",
       "      <td>[\\n  \"Jason Statham\",\\n  \"Sylvester Stallone\",...</td>\n",
       "      <td>[\\n  \"Jason Statham\",\\n  \"Jeffrey Greenstein\",...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm1045025</td>\n",
       "      <td>65</td>\n",
       "      <td>en</td>\n",
       "      <td>491</td>\n",
       "      <td>[\\n  \"action\",\\n  \"drama\",\\n  \"scifi\",\\n  \"thr...</td>\n",
       "      <td>[\\n  \"Bryan Woods\",\\n  \"Scott Beck\"\\n]</td>\n",
       "      <td>[\\n  \"Adam Driver\",\\n  \"Ariana Greenblatt\",\\n ...</td>\n",
       "      <td>[\\n  \"Bryan Woods\",\\n  \"Deborah Liebling\",\\n  ...</td>\n",
       "      <td>[\\n  \"Bryan Woods\",\\n  \"Scott Beck\"\\n]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interactions DataFrame:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                              BE_ID  TITLE_ID  \\\n",
       "0  89ce5486cfd135f81edd5f2cc4013e1e  tm122846   \n",
       "1  5437456587e85d0b97070ea63f459e49  tm172163   \n",
       "2  98c21bf80a45fbfef9902508aba52cdc   ts22280   \n",
       "3  a4fe1d6790b12ef00f5a81631b69a437  ts416258   \n",
       "4  69cf67f4676a77d6ead478f60d84a493   ts15366   \n",
       "\n",
       "                   COLLECTOR_TSTAMP   INTERACTION_TYPE  \n",
       "0  2024-04-06 21:37:50.666000+00:00  clickout_provider  \n",
       "1  2024-04-07 02:08:27.618000+00:00  seenlist_addition  \n",
       "2  2024-04-14 05:23:09.304000+00:00  seenlist_addition  \n",
       "3  2024-04-07 07:34:54.506000+00:00  seenlist_addition  \n",
       "4  2024-04-08 08:29:22.511000+00:00  seenlist_addition  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BE_ID</th>\n",
       "      <th>TITLE_ID</th>\n",
       "      <th>COLLECTOR_TSTAMP</th>\n",
       "      <th>INTERACTION_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89ce5486cfd135f81edd5f2cc4013e1e</td>\n",
       "      <td>tm122846</td>\n",
       "      <td>2024-04-06 21:37:50.666000+00:00</td>\n",
       "      <td>clickout_provider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5437456587e85d0b97070ea63f459e49</td>\n",
       "      <td>tm172163</td>\n",
       "      <td>2024-04-07 02:08:27.618000+00:00</td>\n",
       "      <td>seenlist_addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>98c21bf80a45fbfef9902508aba52cdc</td>\n",
       "      <td>ts22280</td>\n",
       "      <td>2024-04-14 05:23:09.304000+00:00</td>\n",
       "      <td>seenlist_addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a4fe1d6790b12ef00f5a81631b69a437</td>\n",
       "      <td>ts416258</td>\n",
       "      <td>2024-04-07 07:34:54.506000+00:00</td>\n",
       "      <td>seenlist_addition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>69cf67f4676a77d6ead478f60d84a493</td>\n",
       "      <td>ts15366</td>\n",
       "      <td>2024-04-08 08:29:22.511000+00:00</td>\n",
       "      <td>seenlist_addition</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Defining Ideal Recommendations\n",
    "\n",
    "For each specified title, we'll identify users who:\n",
    "\n",
    "1. **Interacted** with the title.\n",
    "2. **Have at least one additional interaction** after that.\n",
    "\n",
    "For each user, we gather all interactions that happen after the interaction with the given title.\n",
    "For each user, we will treat all these subsequent interactions as relevant items.\n",
    "We'll compute metrics like precision@k, recall@k, mean_average_precision, and mean_average_recall for each user, with k being the number of relevant items for that user.\n",
    "We'll aggregate the results across all users.\n",
    "\n",
    "#### Titles of Interest:\n",
    "\n",
    "- **tm107473**: *Morning Glory*\n",
    "- **tm50355**: *The Right Stuff*\n",
    "- **ts89259**: *The Queen's Gambit*\n"
   ],
   "id": "46cbb9c9934ff2e8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:02:18.590274Z",
     "start_time": "2024-10-15T19:02:09.659582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "def str_to_list(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return ['Unknown']\n",
    "    \n",
    "titles= titles_df\n",
    "interactions = interactions_df\n",
    "\n",
    "\n",
    "multivalued_columns = ['GENRE_TMDB', 'DIRECTOR', 'ACTOR', 'PRODUCER']\n",
    "for col in multivalued_columns:\n",
    "    titles[col] = titles[col].apply(str_to_list)\n",
    "\n",
    "\n",
    "def get_top_items(column, min_count):\n",
    "    all_items = titles.explode(column)[column]\n",
    "    item_counts = all_items.value_counts()\n",
    "    top_items = item_counts[item_counts >= min_count].index.tolist()\n",
    "    return top_items\n",
    "\n",
    "# Thresholds\n",
    "director_min_count = 5\n",
    "actor_min_count = 10\n",
    "producer_min_count = 5\n",
    "\n",
    "# Get top items\n",
    "top_directors = get_top_items('DIRECTOR', director_min_count)\n",
    "top_actors = get_top_items('ACTOR', actor_min_count)\n",
    "top_producers = get_top_items('PRODUCER', producer_min_count)\n",
    "\n",
    "# Replace less frequent items\n",
    "def replace_less_frequent(items, top_items):\n",
    "    return [item if item in top_items else 'other' for item in items]\n",
    "\n",
    "titles['DIRECTOR'] = titles['DIRECTOR'].apply(lambda x: replace_less_frequent(x, top_directors))\n",
    "titles['ACTOR'] = titles['ACTOR'].apply(lambda x: replace_less_frequent(x, top_actors))\n",
    "titles['PRODUCER'] = titles['PRODUCER'].apply(lambda x: replace_less_frequent(x, top_producers))\n",
    "\n",
    "\n",
    "# Ensure the 'reference_date' is a valid datetime\n",
    "reference_date = pd.to_datetime(interactions['COLLECTOR_TSTAMP'].max(), errors='coerce', utc=True)\n",
    "\n",
    "# Convert 'RELEASE_DURATION_DAYS' to numeric, drop NaNs, and convert to timedelta\n",
    "titles['RELEASE_DURATION_DAYS'] = pd.to_numeric(titles['RELEASE_DURATION_DAYS'], errors='coerce')\n",
    "titles = titles.dropna(subset=['RELEASE_DURATION_DAYS'])  # Drop rows with NaN after conversion\n",
    "\n",
    "# Step 2: Identify extreme values (filter out values beyond 100 years)\n",
    "threshold_days = pd.to_numeric(pd.Timedelta(days=36500).days)  # Convert 100 years to days and then to numeric\n",
    "extreme_titles = titles[titles['RELEASE_DURATION_DAYS'] > threshold_days]\n",
    "print(f\"Number of titles with extreme RELEASE_DURATION_DAYS: {len(extreme_titles)}\")\n",
    "\n",
    "# Option A: Remove titles with extreme values\n",
    "titles = titles[titles['RELEASE_DURATION_DAYS'] <= threshold_days]\n",
    "\n",
    "# Convert 'RELEASE_DURATION_DAYS' to timedelta only after removing extreme values\n",
    "titles['RELEASE_DURATION_DAYS'] = pd.to_timedelta(titles['RELEASE_DURATION_DAYS'], unit='D')\n",
    "\n",
    "# Step 3: Calculate 'RELEASE_DATE' by subtracting 'RELEASE_DURATION_DAYS' from 'reference_date'\n",
    "titles['RELEASE_DATE'] = reference_date - titles['RELEASE_DURATION_DAYS']\n",
    "\n",
    "# Ensure 'RELEASE_DATE' is valid datetime\n",
    "titles['RELEASE_DATE'] = pd.to_datetime(titles['RELEASE_DATE'], errors='coerce', utc=True)\n",
    "\n",
    "# Step 4: Drop rows with invalid 'RELEASE_DATE' values (NaT values)\n",
    "titles = titles.dropna(subset=['RELEASE_DATE'])\n",
    "\n",
    "# Step 5: Reset index of titles to ensure indices are from 0 to N-1\n",
    "titles = titles.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create mapping from TITLE_ID to index\n",
    "title_id_to_idx = pd.Series(titles.index, index=titles['TITLE_ID']).drop_duplicates()\n",
    "\n",
    "# Create reverse mapping from index to TITLE_ID\n",
    "idx_to_title_id = pd.Series(titles['TITLE_ID'].values, index=titles.index)\n"
   ],
   "id": "279aecdc13273057",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles with extreme RELEASE_DURATION_DAYS: 33\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:42:38.020579Z",
     "start_time": "2024-10-15T19:41:41.801058Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "from src.evaluation.metrics import precision_at_k, recall_at_k, f_score_at_k, ndcg_at_k, mean_average_precision, area_under_roc_curve\n",
    "\n",
    "# Define the titles of interest\n",
    "title_ids = ['tm107473', 'tm50355', 'ts89259']\n",
    "\n",
    "# Define weights for each feature\n",
    "weights = {\n",
    "    'ORIGINAL_TITLE': 0.3,\n",
    "    'GENRE_TMDB': 0.3,\n",
    "    'DIRECTOR': 0.2,\n",
    "    'ACTOR': 0.1,\n",
    "    'PRODUCER': 0.1\n",
    "}\n",
    "\n",
    "# Initialize lists to store the TF-IDF matrices and their weights\n",
    "tfidf_matrices = []\n",
    "feature_weights = []\n",
    "\n",
    "# Generate TF-IDF matrices for each feature and apply the weights\n",
    "for feature, weight in weights.items():\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    # Replace NaN values with an empty string\n",
    "    tfidf_matrix = tfidf.fit_transform(titles[feature].fillna('').apply(lambda x: ' '.join(x) if isinstance(x, list) else x))\n",
    "    tfidf_matrices.append(tfidf_matrix)\n",
    "    feature_weights.append(weight)\n",
    "\n",
    "# Combine the TF-IDF matrices into a single weighted matrix\n",
    "weighted_tfidf_matrix = hstack([tfidf_matrix * weight for tfidf_matrix, weight in zip(tfidf_matrices, feature_weights)])\n",
    "\n",
    "print(f\"Weighted TF-IDF Matrix Shape: {weighted_tfidf_matrix.shape}\")\n",
    "\n",
    "# Apply TruncatedSVD to reduce dimensions\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_matrix_svd = svd.fit_transform(weighted_tfidf_matrix)\n",
    "print(f\"Reduced TF-IDF Matrix Shape: {tfidf_matrix_svd.shape}\")\n",
    "\n",
    "# Generate cosine similarity matrix\n",
    "cosine_sim_svd = cosine_similarity(tfidf_matrix_svd, tfidf_matrix_svd)\n",
    "\n",
    "# Initialize a dictionary to hold ideal recommendations per title\n",
    "ideal_recommendations = {title_id: {} for title_id in title_ids}\n",
    "\n",
    "# Initialize metrics dictionaries to hold user-specific metrics\n",
    "user_metrics = {title_id: [] for title_id in title_ids}\n",
    "\n",
    "# Initialize list to store the final average metrics for each title\n",
    "title_results = []\n",
    "\n",
    "# Iterate over each title to identify ideal recommendations and calculate metrics\n",
    "for title_id in tqdm(title_ids, desc=\"Processing Titles\"):\n",
    "    # Find all interactions with the title\n",
    "    title_interactions = interactions_df[interactions_df['TITLE_ID'] == title_id]\n",
    "    \n",
    "    # Get user IDs who interacted with the title (limit to 100 users)\n",
    "    users_who_interacted = title_interactions['BE_ID'].unique()[:20]  # Limit to 100 users\n",
    "\n",
    "    # Progress bar for users\n",
    "    for user_id in tqdm(users_who_interacted, desc=f\"Processing users for title {title_id}\", leave=False):\n",
    "        # Get all interactions of the user sorted by timestamp\n",
    "        user_interactions = interactions_df[interactions_df['BE_ID'] == user_id].sort_values('COLLECTOR_TSTAMP')\n",
    "        \n",
    "        # Find the interaction index with the current title\n",
    "        title_indices = user_interactions[user_interactions['TITLE_ID'] == title_id].index\n",
    "        \n",
    "        # For each interaction with the title, find all subsequent interactions\n",
    "        relevant_interactions = []\n",
    "        for idx in title_indices:\n",
    "            # Get the position of the title interaction\n",
    "            pos = user_interactions.index.get_loc(idx)\n",
    "            \n",
    "            # Get all interactions after the title interaction\n",
    "            if pos + 1 < len(user_interactions):\n",
    "                relevant_interactions.extend(user_interactions.iloc[pos + 1:]['TITLE_ID'].tolist())\n",
    "\n",
    "        # Calculate metrics if the user has relevant interactions\n",
    "        if relevant_interactions:\n",
    "            # Store all relevant interactions as ideal recommendations for the user\n",
    "            ideal_recommendations[title_id][user_id] = relevant_interactions\n",
    "            \n",
    "            # Find the cosine similarity for the title and recommend similar titles\n",
    "            title_idx = titles[titles['TITLE_ID'] == title_id].index[0]\n",
    "            sim_scores = list(enumerate(cosine_sim_svd[title_idx]))\n",
    "            sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "            \n",
    "            # Get top K recommendations based on cosine similarity\n",
    "            recommended_indices = [i[0] for i in sim_scores[1:]]  # Exclude the title itself\n",
    "            predicted_recommendations = [titles.iloc[i]['TITLE_ID'] for i in recommended_indices[:min(len(relevant_interactions), 10)]]\n",
    "\n",
    "            # Set k to the minimum of relevant_interactions count and predefined k=10\n",
    "            k = min(len(relevant_interactions), 10)\n",
    "\n",
    "            # Calculate metrics using functions from metrics.py with the adjusted k\n",
    "            precision = precision_at_k(predicted_recommendations, relevant_interactions, k=k)\n",
    "            recall = recall_at_k(predicted_recommendations, relevant_interactions, k=k)\n",
    "            f1_score = f_score_at_k(precision, recall)\n",
    "            ndcg = ndcg_at_k(predicted_recommendations, relevant_interactions, k=k)\n",
    "            map_score = mean_average_precision(predicted_recommendations, relevant_interactions, k=k)\n",
    "            \n",
    "            # Append user-specific metrics\n",
    "            user_metrics[title_id].append({\n",
    "                'user_id': user_id,\n",
    "                'precision@k': precision,\n",
    "                'recall@k': recall,\n",
    "                'f1_score@k': f1_score,\n",
    "                'ndcg@k': ndcg,\n",
    "                'mean_avg_precision': map_score,\n",
    "                'relevant_interactions': relevant_interactions,\n",
    "                'predicted_recommendations': predicted_recommendations\n",
    "            })\n",
    "\n",
    "    # Calculate average metrics for the title\n",
    "    if user_metrics[title_id]:\n",
    "        df_metrics = pd.DataFrame(user_metrics[title_id])\n",
    "        avg_precision = df_metrics['precision@k'].mean()\n",
    "        avg_recall = df_metrics['recall@k'].mean()\n",
    "        avg_f1_score = df_metrics['f1_score@k'].mean()\n",
    "        avg_ndcg = df_metrics['ndcg@k'].mean()\n",
    "        avg_map = df_metrics['mean_avg_precision'].mean()\n",
    "        avg_auc = df_metrics['auc'].mean()\n",
    "\n",
    "        # Append title-level metrics to the final results\n",
    "        title_results.append({\n",
    "            'title_id': title_id,\n",
    "            'avg_precision@k': avg_precision,\n",
    "            'avg_recall@k': avg_recall,\n",
    "            'avg_f1_score@k': avg_f1_score,\n",
    "            'avg_ndcg@k': avg_ndcg,\n",
    "            'avg_mean_avg_precision': avg_map,\n",
    "            'avg_auc': avg_auc\n",
    "        })\n",
    "\n",
    "# Convert title results to DataFrame\n",
    "results_df = pd.DataFrame(title_results)\n",
    "print(\"Average Metrics per Title:\")\n",
    "display(results_df)\n",
    "\n",
    "# Display ideal recommendations for each title\n",
    "for title_id in title_ids:\n",
    "    print(f\"Ideal Recommendations for Title ID {title_id}:\")\n",
    "    display(pd.DataFrame.from_dict(ideal_recommendations[title_id], orient='index', columns=['Ideal Recommendations']).head())\n"
   ],
   "id": "917349bb83c93ee0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted TF-IDF Matrix Shape: (20596, 16880)\n",
      "Reduced TF-IDF Matrix Shape: (20596, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Titles:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "Processing users for title tm107473:   0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Processing users for title tm107473:   5%|▌         | 1/20 [00:02<00:40,  2.14s/it]\u001B[A\n",
      "Processing users for title tm107473:  10%|█         | 2/20 [00:02<00:19,  1.10s/it]\u001B[A\n",
      "Processing users for title tm107473:  15%|█▌        | 3/20 [00:03<00:15,  1.12it/s]\u001B[A\n",
      "Processing users for title tm107473:  20%|██        | 4/20 [00:04<00:14,  1.13it/s]\u001B[A\n",
      "Processing users for title tm107473:  25%|██▌       | 5/20 [00:04<00:11,  1.26it/s]\u001B[A\n",
      "Processing users for title tm107473:  30%|███       | 6/20 [00:05<00:10,  1.34it/s]\u001B[A\n",
      "Processing users for title tm107473:  35%|███▌      | 7/20 [00:06<00:11,  1.13it/s]\u001B[A\n",
      "Processing users for title tm107473:  40%|████      | 8/20 [00:06<00:08,  1.34it/s]\u001B[A\n",
      "Processing users for title tm107473:  45%|████▌     | 9/20 [00:07<00:07,  1.50it/s]\u001B[A\n",
      "Processing users for title tm107473:  50%|█████     | 10/20 [00:07<00:05,  1.71it/s]\u001B[A\n",
      "Processing users for title tm107473:  55%|█████▌    | 11/20 [00:08<00:04,  1.91it/s]\u001B[A\n",
      "Processing users for title tm107473:  60%|██████    | 12/20 [00:08<00:03,  2.07it/s]\u001B[A\n",
      "Processing users for title tm107473:  65%|██████▌   | 13/20 [00:08<00:03,  2.25it/s]\u001B[A\n",
      "Processing users for title tm107473:  70%|███████   | 14/20 [00:09<00:02,  2.39it/s]\u001B[A\n",
      "Processing users for title tm107473:  75%|███████▌  | 15/20 [00:10<00:02,  1.90it/s]\u001B[A\n",
      "Processing users for title tm107473:  80%|████████  | 16/20 [00:10<00:02,  1.89it/s]\u001B[A\n",
      "Processing users for title tm107473:  85%|████████▌ | 17/20 [00:11<00:01,  1.68it/s]\u001B[A\n",
      "Processing users for title tm107473:  90%|█████████ | 18/20 [00:14<00:02,  1.32s/it]\u001B[A\n",
      "Processing users for title tm107473:  95%|█████████▌| 19/20 [00:15<00:01,  1.23s/it]\u001B[A\n",
      "Processing users for title tm107473: 100%|██████████| 20/20 [00:20<00:00,  2.51s/it]\u001B[A\n",
      "Processing Titles:  33%|███▎      | 1/3 [00:28<00:57, 28.62s/it]                    \u001B[A\n",
      "Processing users for title tm50355:   0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Processing users for title tm50355:   5%|▌         | 1/20 [00:02<00:38,  2.04s/it]\u001B[A\n",
      "Processing users for title tm50355:  10%|█         | 2/20 [00:02<00:23,  1.31s/it]\u001B[A\n",
      "Processing users for title tm50355:  15%|█▌        | 3/20 [00:03<00:18,  1.09s/it]\u001B[A\n",
      "Processing users for title tm50355:  20%|██        | 4/20 [00:04<00:15,  1.00it/s]\u001B[A\n",
      "Processing users for title tm50355:  25%|██▌       | 5/20 [00:05<00:12,  1.22it/s]\u001B[A\n",
      "Processing users for title tm50355:  30%|███       | 6/20 [00:05<00:09,  1.49it/s]\u001B[A\n",
      "Processing users for title tm50355:  35%|███▌      | 7/20 [00:06<00:09,  1.36it/s]\u001B[A\n",
      "Processing users for title tm50355:  40%|████      | 8/20 [00:06<00:07,  1.52it/s]\u001B[A\n",
      "Processing users for title tm50355:  45%|████▌     | 9/20 [00:07<00:06,  1.76it/s]\u001B[A\n",
      "Processing users for title tm50355:  50%|█████     | 10/20 [00:07<00:05,  1.94it/s]\u001B[A\n",
      "Processing users for title tm50355:  55%|█████▌    | 11/20 [00:07<00:04,  2.02it/s]\u001B[A\n",
      "Processing users for title tm50355:  60%|██████    | 12/20 [00:08<00:03,  2.17it/s]\u001B[A\n",
      "Processing users for title tm50355:  65%|██████▌   | 13/20 [00:08<00:03,  2.26it/s]\u001B[A\n",
      "Processing users for title tm50355:  70%|███████   | 14/20 [00:09<00:03,  1.98it/s]\u001B[A\n",
      "Processing users for title tm50355:  75%|███████▌  | 15/20 [00:09<00:02,  2.00it/s]\u001B[A\n",
      "Processing users for title tm50355:  80%|████████  | 16/20 [00:10<00:01,  2.16it/s]\u001B[A\n",
      "Processing users for title tm50355:  85%|████████▌ | 17/20 [00:10<00:01,  2.19it/s]\u001B[A\n",
      "Processing users for title tm50355:  90%|█████████ | 18/20 [00:11<00:00,  2.29it/s]\u001B[A\n",
      "Processing users for title tm50355:  95%|█████████▌| 19/20 [00:11<00:00,  2.35it/s]\u001B[A\n",
      "Processing users for title tm50355: 100%|██████████| 20/20 [00:11<00:00,  2.46it/s]\u001B[A\n",
      "Processing Titles:  67%|██████▋   | 2/3 [00:42<00:19, 19.81s/it]                   \u001B[A\n",
      "Processing users for title ts89259:   0%|          | 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Processing users for title ts89259:   5%|▌         | 1/20 [00:00<00:09,  1.98it/s]\u001B[A\n",
      "Processing users for title ts89259:  10%|█         | 2/20 [00:00<00:08,  2.19it/s]\u001B[A\n",
      "Processing users for title ts89259:  15%|█▌        | 3/20 [00:01<00:07,  2.25it/s]\u001B[A\n",
      "Processing users for title ts89259:  20%|██        | 4/20 [00:01<00:06,  2.41it/s]\u001B[A\n",
      "Processing users for title ts89259:  25%|██▌       | 5/20 [00:02<00:05,  2.53it/s]\u001B[A\n",
      "Processing users for title ts89259:  30%|███       | 6/20 [00:02<00:05,  2.57it/s]\u001B[A\n",
      "Processing users for title ts89259:  35%|███▌      | 7/20 [00:02<00:05,  2.58it/s]\u001B[A\n",
      "Processing users for title ts89259:  40%|████      | 8/20 [00:03<00:04,  2.62it/s]\u001B[A\n",
      "Processing users for title ts89259:  45%|████▌     | 9/20 [00:03<00:04,  2.70it/s]\u001B[A\n",
      "Processing users for title ts89259:  50%|█████     | 10/20 [00:03<00:03,  2.72it/s]\u001B[A\n",
      "Processing users for title ts89259:  55%|█████▌    | 11/20 [00:04<00:03,  2.75it/s]\u001B[A\n",
      "Processing users for title ts89259:  60%|██████    | 12/20 [00:04<00:02,  2.81it/s]\u001B[A\n",
      "Processing users for title ts89259:  65%|██████▌   | 13/20 [00:04<00:02,  2.80it/s]\u001B[A\n",
      "Processing users for title ts89259:  70%|███████   | 14/20 [00:05<00:02,  2.78it/s]\u001B[A\n",
      "Processing users for title ts89259:  75%|███████▌  | 15/20 [00:05<00:01,  2.78it/s]\u001B[A\n",
      "Processing users for title ts89259:  80%|████████  | 16/20 [00:06<00:01,  2.78it/s]\u001B[A\n",
      "Processing users for title ts89259:  85%|████████▌ | 17/20 [00:06<00:01,  2.82it/s]\u001B[A\n",
      "Processing users for title ts89259:  90%|█████████ | 18/20 [00:06<00:00,  2.85it/s]\u001B[A\n",
      "Processing users for title ts89259:  95%|█████████▌| 19/20 [00:07<00:00,  2.88it/s]\u001B[A\n",
      "Processing users for title ts89259: 100%|██████████| 20/20 [00:07<00:00,  2.34it/s]\u001B[A\n",
      "Processing Titles: 100%|██████████| 3/3 [00:50<00:00, 16.83s/it]                   \u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metrics per Title:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   title_id  avg_precision@k  avg_recall@k  avg_f1_score@k  avg_ndcg@k  \\\n",
       "0  tm107473            0.015      0.000658        0.001245    0.013305   \n",
       "1   tm50355            0.000      0.000000        0.000000    0.000000   \n",
       "2   ts89259            0.000      0.000000        0.000000    0.000000   \n",
       "\n",
       "   avg_mean_avg_precision   avg_auc  \n",
       "0                0.000105  0.500116  \n",
       "1                0.000000  0.499785  \n",
       "2                0.000000  0.499756  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_id</th>\n",
       "      <th>avg_precision@k</th>\n",
       "      <th>avg_recall@k</th>\n",
       "      <th>avg_f1_score@k</th>\n",
       "      <th>avg_ndcg@k</th>\n",
       "      <th>avg_mean_avg_precision</th>\n",
       "      <th>avg_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm107473</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.013305</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.500116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm50355</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ts89259</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.499756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ideal Recommendations for Title ID tm107473:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1 columns passed, passed data had 863 columns",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:939\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[0;34m(content, columns, dtype)\u001B[0m\n\u001B[1;32m    938\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 939\u001B[0m     columns \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_or_indexify_columns\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcontents\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:986\u001B[0m, in \u001B[0;36m_validate_or_indexify_columns\u001B[0;34m(content, columns)\u001B[0m\n\u001B[1;32m    984\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_mi_list \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(columns) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(content):  \u001B[38;5;66;03m# pragma: no cover\u001B[39;00m\n\u001B[1;32m    985\u001B[0m     \u001B[38;5;66;03m# caller's responsibility to check for this...\u001B[39;00m\n\u001B[0;32m--> 986\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m(\n\u001B[1;32m    987\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(columns)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns passed, passed data had \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    988\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(content)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m columns\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    989\u001B[0m     )\n\u001B[1;32m    990\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_mi_list:\n\u001B[1;32m    991\u001B[0m     \u001B[38;5;66;03m# check if nested list column, length of each sub-list should be equal\u001B[39;00m\n",
      "\u001B[0;31mAssertionError\u001B[0m: 1 columns passed, passed data had 863 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 149\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m title_id \u001B[38;5;129;01min\u001B[39;00m title_ids:\n\u001B[1;32m    148\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIdeal Recommendations for Title ID \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtitle_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 149\u001B[0m     display(\u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDataFrame\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_dict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mideal_recommendations\u001B[49m\u001B[43m[\u001B[49m\u001B[43mtitle_id\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morient\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mindex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mIdeal Recommendations\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mhead())\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/frame.py:1917\u001B[0m, in \u001B[0;36mDataFrame.from_dict\u001B[0;34m(cls, data, orient, dtype, columns)\u001B[0m\n\u001B[1;32m   1911\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1912\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcolumns\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m or \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtight\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m for orient parameter. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1913\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGot \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00morient\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m instead\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1914\u001B[0m     )\n\u001B[1;32m   1916\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m orient \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtight\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 1917\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1918\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1919\u001B[0m     realdata \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/frame.py:851\u001B[0m, in \u001B[0;36mDataFrame.__init__\u001B[0;34m(self, data, index, columns, dtype, copy)\u001B[0m\n\u001B[1;32m    849\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    850\u001B[0m         columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[0;32m--> 851\u001B[0m     arrays, columns, index \u001B[38;5;241m=\u001B[39m \u001B[43mnested_data_to_arrays\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    852\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001B[39;49;00m\n\u001B[1;32m    853\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001B[39;49;00m\n\u001B[1;32m    854\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    855\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    856\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[1;32m    857\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    858\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    859\u001B[0m     mgr \u001B[38;5;241m=\u001B[39m arrays_to_mgr(\n\u001B[1;32m    860\u001B[0m         arrays,\n\u001B[1;32m    861\u001B[0m         columns,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    864\u001B[0m         typ\u001B[38;5;241m=\u001B[39mmanager,\n\u001B[1;32m    865\u001B[0m     )\n\u001B[1;32m    866\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:520\u001B[0m, in \u001B[0;36mnested_data_to_arrays\u001B[0;34m(data, columns, index, dtype)\u001B[0m\n\u001B[1;32m    517\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_named_tuple(data[\u001B[38;5;241m0\u001B[39m]) \u001B[38;5;129;01mand\u001B[39;00m columns \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    518\u001B[0m     columns \u001B[38;5;241m=\u001B[39m ensure_index(data[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_fields)\n\u001B[0;32m--> 520\u001B[0m arrays, columns \u001B[38;5;241m=\u001B[39m \u001B[43mto_arrays\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    521\u001B[0m columns \u001B[38;5;241m=\u001B[39m ensure_index(columns)\n\u001B[1;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m index \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:845\u001B[0m, in \u001B[0;36mto_arrays\u001B[0;34m(data, columns, dtype)\u001B[0m\n\u001B[1;32m    842\u001B[0m     data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mtuple\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m data]\n\u001B[1;32m    843\u001B[0m     arr \u001B[38;5;241m=\u001B[39m _list_to_arrays(data)\n\u001B[0;32m--> 845\u001B[0m content, columns \u001B[38;5;241m=\u001B[39m \u001B[43m_finalize_columns_and_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    846\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m content, columns\n",
      "File \u001B[0;32m~/repos/simple_recommendation_system/venv/lib/python3.11/site-packages/pandas/core/internals/construction.py:942\u001B[0m, in \u001B[0;36m_finalize_columns_and_data\u001B[0;34m(content, columns, dtype)\u001B[0m\n\u001B[1;32m    939\u001B[0m     columns \u001B[38;5;241m=\u001B[39m _validate_or_indexify_columns(contents, columns)\n\u001B[1;32m    940\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAssertionError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;66;03m# GH#26429 do not raise user-facing AssertionError\u001B[39;00m\n\u001B[0;32m--> 942\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(err) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m    944\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(contents) \u001B[38;5;129;01mand\u001B[39;00m contents[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mobject_:\n\u001B[1;32m    945\u001B[0m     contents \u001B[38;5;241m=\u001B[39m convert_object_array(contents, dtype\u001B[38;5;241m=\u001B[39mdtype)\n",
      "\u001B[0;31mValueError\u001B[0m: 1 columns passed, passed data had 863 columns"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Generating Current Recommendations\n",
    "\n",
    "We'll now generate recommendations using our **Content-Based Weighted** recommender for the specified titles. We'll compare these recommendations against the ideal recommendations defined earlier.\n"
   ],
   "id": "a67611574e85c251"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:43:21.303513Z",
     "start_time": "2024-10-15T14:43:11.943824Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ast\n",
    "def str_to_list(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x)\n",
    "    except:\n",
    "        return ['Unknown']\n",
    "    \n",
    "titles= titles_df\n",
    "interactions = interactions_df\n",
    "\n",
    "\n",
    "multivalued_columns = ['GENRE_TMDB', 'DIRECTOR', 'ACTOR', 'PRODUCER']\n",
    "for col in multivalued_columns:\n",
    "    titles[col] = titles[col].apply(str_to_list)\n",
    "\n",
    "\n",
    "def get_top_items(column, min_count):\n",
    "    all_items = titles.explode(column)[column]\n",
    "    item_counts = all_items.value_counts()\n",
    "    top_items = item_counts[item_counts >= min_count].index.tolist()\n",
    "    return top_items\n",
    "\n",
    "# Thresholds\n",
    "director_min_count = 5\n",
    "actor_min_count = 10\n",
    "producer_min_count = 5\n",
    "\n",
    "# Get top items\n",
    "top_directors = get_top_items('DIRECTOR', director_min_count)\n",
    "top_actors = get_top_items('ACTOR', actor_min_count)\n",
    "top_producers = get_top_items('PRODUCER', producer_min_count)\n",
    "\n",
    "# Replace less frequent items\n",
    "def replace_less_frequent(items, top_items):\n",
    "    return [item if item in top_items else 'other' for item in items]\n",
    "\n",
    "titles['DIRECTOR'] = titles['DIRECTOR'].apply(lambda x: replace_less_frequent(x, top_directors))\n",
    "titles['ACTOR'] = titles['ACTOR'].apply(lambda x: replace_less_frequent(x, top_actors))\n",
    "titles['PRODUCER'] = titles['PRODUCER'].apply(lambda x: replace_less_frequent(x, top_producers))\n",
    "\n",
    "\n",
    "# Ensure the 'reference_date' is a valid datetime\n",
    "reference_date = pd.to_datetime(interactions['COLLECTOR_TSTAMP'].max(), errors='coerce', utc=True)\n",
    "\n",
    "# Convert 'RELEASE_DURATION_DAYS' to numeric, drop NaNs, and convert to timedelta\n",
    "titles['RELEASE_DURATION_DAYS'] = pd.to_numeric(titles['RELEASE_DURATION_DAYS'], errors='coerce')\n",
    "titles = titles.dropna(subset=['RELEASE_DURATION_DAYS'])  # Drop rows with NaN after conversion\n",
    "\n",
    "# Step 2: Identify extreme values (filter out values beyond 100 years)\n",
    "threshold_days = pd.to_numeric(pd.Timedelta(days=36500).days)  # Convert 100 years to days and then to numeric\n",
    "extreme_titles = titles[titles['RELEASE_DURATION_DAYS'] > threshold_days]\n",
    "print(f\"Number of titles with extreme RELEASE_DURATION_DAYS: {len(extreme_titles)}\")\n",
    "\n",
    "# Option A: Remove titles with extreme values\n",
    "titles = titles[titles['RELEASE_DURATION_DAYS'] <= threshold_days]\n",
    "\n",
    "# Convert 'RELEASE_DURATION_DAYS' to timedelta only after removing extreme values\n",
    "titles['RELEASE_DURATION_DAYS'] = pd.to_timedelta(titles['RELEASE_DURATION_DAYS'], unit='D')\n",
    "\n",
    "# Step 3: Calculate 'RELEASE_DATE' by subtracting 'RELEASE_DURATION_DAYS' from 'reference_date'\n",
    "titles['RELEASE_DATE'] = reference_date - titles['RELEASE_DURATION_DAYS']\n",
    "\n",
    "# Ensure 'RELEASE_DATE' is valid datetime\n",
    "titles['RELEASE_DATE'] = pd.to_datetime(titles['RELEASE_DATE'], errors='coerce', utc=True)\n",
    "\n",
    "# Step 4: Drop rows with invalid 'RELEASE_DATE' values (NaT values)\n",
    "titles = titles.dropna(subset=['RELEASE_DATE'])\n",
    "\n",
    "# Step 5: Reset index of titles to ensure indices are from 0 to N-1\n",
    "titles = titles.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Create mapping from TITLE_ID to index\n",
    "title_id_to_idx = pd.Series(titles.index, index=titles['TITLE_ID']).drop_duplicates()\n",
    "\n",
    "# Create reverse mapping from index to TITLE_ID\n",
    "idx_to_title_id = pd.Series(titles['TITLE_ID'].values, index=titles.index)\n"
   ],
   "id": "2ebf4d1687138499",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of titles with extreme RELEASE_DURATION_DAYS: 33\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:45:30.642544Z",
     "start_time": "2024-10-15T14:45:30.613723Z"
    }
   },
   "cell_type": "code",
   "source": "titles = titles.drop(columns=['WRITER'])",
   "id": "d9994bb6ef6f086e",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:45:32.333351Z",
     "start_time": "2024-10-15T14:45:32.303640Z"
    }
   },
   "cell_type": "code",
   "source": "titles",
   "id": "2fde3b6d6644e8d2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        TITLE_ID           ORIGINAL_TITLE ORIGINAL_LANGUAGE  \\\n",
       "0      tm1282307  L'ultima notte di Amore                it   \n",
       "1      tm1338500       Bird Box Barcelona                es   \n",
       "2       ts371824        Steeltown Murders                en   \n",
       "3       tm123363              Expend4bles                en   \n",
       "4      tm1045025                       65                en   \n",
       "...          ...                      ...               ...   \n",
       "20591    ts21325                   Hunter                en   \n",
       "20592  tm1382322          Strange Darling                en   \n",
       "20593    ts21242      Mission: Impossible                en   \n",
       "20594    ts37497        Popeye the Sailor                en   \n",
       "20595   tm188638                    Gypsy                en   \n",
       "\n",
       "      RELEASE_DURATION_DAYS                            GENRE_TMDB  \\\n",
       "0                  484 days                     [drama, thriller]   \n",
       "1                  357 days             [horror, scifi, thriller]   \n",
       "2                  417 days     [crime, drama, history, thriller]   \n",
       "3                  294 days               [action, thriller, war]   \n",
       "4                  491 days      [action, drama, scifi, thriller]   \n",
       "...                     ...                                   ...   \n",
       "20591            14535 days      [action, crime, drama, thriller]   \n",
       "20592              -49 days                    [horror, thriller]   \n",
       "20593            21111 days      [action, crime, drama, thriller]   \n",
       "20594            23401 days  [animation, comedy, family, romance]   \n",
       "20595            11163 days                [comedy, drama, music]   \n",
       "\n",
       "                                                DIRECTOR  \\\n",
       "0                                                [other]   \n",
       "1                                         [other, other]   \n",
       "2                                                [other]   \n",
       "3                                                [other]   \n",
       "4                                         [other, other]   \n",
       "...                                                  ...   \n",
       "20591  [David Soul, Tony Mordente, Gus Trikonis, Jame...   \n",
       "20592                                            [other]   \n",
       "20593  [Tom Gries, Leonard J. Horn, Seymour Robbie, H...   \n",
       "20594   [Jack Kinney, other, other, other, other, other]   \n",
       "20595                                   [Emile Ardolino]   \n",
       "\n",
       "                                                   ACTOR  \\\n",
       "0      [Pierfrancesco Favino, other, other, other, ot...   \n",
       "1      [Mario Casas, Georgina Campbell, other, other,...   \n",
       "2      [other, other, other, other, Aneurin Barnard, ...   \n",
       "3      [Jason Statham, Sylvester Stallone, 50 Cent, M...   \n",
       "4              [Adam Driver, other, other, other, other]   \n",
       "...                                                  ...   \n",
       "20591            [other, other, Charles Hallahan, other]   \n",
       "20592  [other, Kyle Gallner, Jason Patric, Giovanni R...   \n",
       "20593                [other, other, other, other, other]   \n",
       "20594                              [other, other, other]   \n",
       "20595  [Bette Midler, other, Elisabeth Moss, other, o...   \n",
       "\n",
       "                                                PRODUCER  \\\n",
       "0      [Benedetto Habib, Daniel Campos Pavoncelli, Fa...   \n",
       "1      [Adrián Guerra, Chris Morgan, Dylan Clark, Núr...   \n",
       "2                                                [other]   \n",
       "3      [other, Jeffrey Greenstein, Jonathan Yunger, K...   \n",
       "4                [other, other, Sam Raimi, other, other]   \n",
       "...                                                  ...   \n",
       "20591  [other, other, other, other, other, Stephen J....   \n",
       "20592     [Bill Block, other, Roy Lee, Steven Schneider]   \n",
       "20593                [other, other, other, other, other]   \n",
       "20594                                            [other]   \n",
       "20595                                     [other, other]   \n",
       "\n",
       "                          RELEASE_DATE  \n",
       "0     2023-03-09 04:29:50.019000+00:00  \n",
       "1     2023-07-14 04:29:50.019000+00:00  \n",
       "2     2023-05-15 04:29:50.019000+00:00  \n",
       "3     2023-09-15 04:29:50.019000+00:00  \n",
       "4     2023-03-02 04:29:50.019000+00:00  \n",
       "...                                ...  \n",
       "20591 1984-09-18 04:29:50.019000+00:00  \n",
       "20592 2024-08-23 04:29:50.019000+00:00  \n",
       "20593 1966-09-17 04:29:50.019000+00:00  \n",
       "20594 1960-06-10 04:29:50.019000+00:00  \n",
       "20595 1993-12-12 04:29:50.019000+00:00  \n",
       "\n",
       "[20596 rows x 9 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TITLE_ID</th>\n",
       "      <th>ORIGINAL_TITLE</th>\n",
       "      <th>ORIGINAL_LANGUAGE</th>\n",
       "      <th>RELEASE_DURATION_DAYS</th>\n",
       "      <th>GENRE_TMDB</th>\n",
       "      <th>DIRECTOR</th>\n",
       "      <th>ACTOR</th>\n",
       "      <th>PRODUCER</th>\n",
       "      <th>RELEASE_DATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm1282307</td>\n",
       "      <td>L'ultima notte di Amore</td>\n",
       "      <td>it</td>\n",
       "      <td>484 days</td>\n",
       "      <td>[drama, thriller]</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[Pierfrancesco Favino, other, other, other, ot...</td>\n",
       "      <td>[Benedetto Habib, Daniel Campos Pavoncelli, Fa...</td>\n",
       "      <td>2023-03-09 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm1338500</td>\n",
       "      <td>Bird Box Barcelona</td>\n",
       "      <td>es</td>\n",
       "      <td>357 days</td>\n",
       "      <td>[horror, scifi, thriller]</td>\n",
       "      <td>[other, other]</td>\n",
       "      <td>[Mario Casas, Georgina Campbell, other, other,...</td>\n",
       "      <td>[Adrián Guerra, Chris Morgan, Dylan Clark, Núr...</td>\n",
       "      <td>2023-07-14 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ts371824</td>\n",
       "      <td>Steeltown Murders</td>\n",
       "      <td>en</td>\n",
       "      <td>417 days</td>\n",
       "      <td>[crime, drama, history, thriller]</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[other, other, other, other, Aneurin Barnard, ...</td>\n",
       "      <td>[other]</td>\n",
       "      <td>2023-05-15 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm123363</td>\n",
       "      <td>Expend4bles</td>\n",
       "      <td>en</td>\n",
       "      <td>294 days</td>\n",
       "      <td>[action, thriller, war]</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[Jason Statham, Sylvester Stallone, 50 Cent, M...</td>\n",
       "      <td>[other, Jeffrey Greenstein, Jonathan Yunger, K...</td>\n",
       "      <td>2023-09-15 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm1045025</td>\n",
       "      <td>65</td>\n",
       "      <td>en</td>\n",
       "      <td>491 days</td>\n",
       "      <td>[action, drama, scifi, thriller]</td>\n",
       "      <td>[other, other]</td>\n",
       "      <td>[Adam Driver, other, other, other, other]</td>\n",
       "      <td>[other, other, Sam Raimi, other, other]</td>\n",
       "      <td>2023-03-02 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20591</th>\n",
       "      <td>ts21325</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>en</td>\n",
       "      <td>14535 days</td>\n",
       "      <td>[action, crime, drama, thriller]</td>\n",
       "      <td>[David Soul, Tony Mordente, Gus Trikonis, Jame...</td>\n",
       "      <td>[other, other, Charles Hallahan, other]</td>\n",
       "      <td>[other, other, other, other, other, Stephen J....</td>\n",
       "      <td>1984-09-18 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20592</th>\n",
       "      <td>tm1382322</td>\n",
       "      <td>Strange Darling</td>\n",
       "      <td>en</td>\n",
       "      <td>-49 days</td>\n",
       "      <td>[horror, thriller]</td>\n",
       "      <td>[other]</td>\n",
       "      <td>[other, Kyle Gallner, Jason Patric, Giovanni R...</td>\n",
       "      <td>[Bill Block, other, Roy Lee, Steven Schneider]</td>\n",
       "      <td>2024-08-23 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20593</th>\n",
       "      <td>ts21242</td>\n",
       "      <td>Mission: Impossible</td>\n",
       "      <td>en</td>\n",
       "      <td>21111 days</td>\n",
       "      <td>[action, crime, drama, thriller]</td>\n",
       "      <td>[Tom Gries, Leonard J. Horn, Seymour Robbie, H...</td>\n",
       "      <td>[other, other, other, other, other]</td>\n",
       "      <td>[other, other, other, other, other]</td>\n",
       "      <td>1966-09-17 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20594</th>\n",
       "      <td>ts37497</td>\n",
       "      <td>Popeye the Sailor</td>\n",
       "      <td>en</td>\n",
       "      <td>23401 days</td>\n",
       "      <td>[animation, comedy, family, romance]</td>\n",
       "      <td>[Jack Kinney, other, other, other, other, other]</td>\n",
       "      <td>[other, other, other]</td>\n",
       "      <td>[other]</td>\n",
       "      <td>1960-06-10 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20595</th>\n",
       "      <td>tm188638</td>\n",
       "      <td>Gypsy</td>\n",
       "      <td>en</td>\n",
       "      <td>11163 days</td>\n",
       "      <td>[comedy, drama, music]</td>\n",
       "      <td>[Emile Ardolino]</td>\n",
       "      <td>[Bette Midler, other, Elisabeth Moss, other, o...</td>\n",
       "      <td>[other, other]</td>\n",
       "      <td>1993-12-12 04:29:50.019000+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20596 rows × 9 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:48:07.191879Z",
     "start_time": "2024-10-15T14:48:01.909119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "# Define weights for each feature\n",
    "weights = {\n",
    "    'ORIGINAL_TITLE': 0.3,\n",
    "    'GENRE_TMDB': 0.3,\n",
    "    'DIRECTOR': 0.2,\n",
    "    'ACTOR': 0.1,\n",
    "    'PRODUCER': 0.1\n",
    "}\n",
    "\n",
    "# Initialize lists to store the TF-IDF matrices and their weights\n",
    "tfidf_matrices = []\n",
    "feature_weights = []\n",
    "\n",
    "# Generate TF-IDF matrices for each feature and apply the weights\n",
    "for feature, weight in weights.items():\n",
    "    tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "    # Replace NaN values with an empty string\n",
    "    tfidf_matrix = tfidf.fit_transform(titles[feature].fillna('').apply(lambda x: ' '.join(x) if isinstance(x, list) else x))\n",
    "    tfidf_matrices.append(tfidf_matrix)\n",
    "    feature_weights.append(weight)\n",
    "\n",
    "# Combine the TF-IDF matrices into a single weighted matrix\n",
    "weighted_tfidf_matrix = hstack([tfidf_matrix * weight for tfidf_matrix, weight in zip(tfidf_matrices, feature_weights)])\n",
    "\n",
    "print(f\"Weighted TF-IDF Matrix Shape: {weighted_tfidf_matrix.shape}\")\n",
    "\n",
    "# Apply TruncatedSVD to reduce dimensions\n",
    "svd = TruncatedSVD(n_components=100, random_state=42)\n",
    "tfidf_matrix_svd = svd.fit_transform(weighted_tfidf_matrix)\n",
    "print(f\"Reduced TF-IDF Matrix Shape: {tfidf_matrix_svd.shape}\")\n",
    "\n",
    "cosine_sim_svd = cosine_similarity(tfidf_matrix_svd, tfidf_matrix_svd)\n"
   ],
   "id": "78d1daefa73dc47e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted TF-IDF Matrix Shape: (20596, 16880)\n",
      "Reduced TF-IDF Matrix Shape: (20596, 100)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:48:53.763551Z",
     "start_time": "2024-10-15T14:48:47.411642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from src.models.content_based import WeightedContentBasedRecommender\n",
    "\n",
    "\n",
    "\n",
    "weighted_content_recommender = WeightedContentBasedRecommender(titles, tfidf_matrix_svd, idx_to_title_id)\n",
    "weighted_content_recommender.train()"
   ],
   "id": "4a3770a678f3d077",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:49:51.150833Z",
     "start_time": "2024-10-15T14:49:50.308104Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_recommendations_for_title(recommender, title_id, top_k=10):\n",
    "    \"\"\"\n",
    "    Generates recommendations for a given title using the specified recommender.\n",
    "    \n",
    "    Parameters:\n",
    "    - recommender: The trained recommender object.\n",
    "    - title_id: The title ID for which to generate recommendations.\n",
    "    - top_k: Number of top recommendations to retrieve.\n",
    "    \n",
    "    Returns:\n",
    "    - List of recommended title IDs.\n",
    "    \"\"\"\n",
    "    recommendations = recommender.get_recommendations(title_id=title_id, top_k=top_k)\n",
    "    return recommendations\n",
    "\n",
    "# Create a dictionary to hold current recommendations per title\n",
    "current_recommendations = {title_id: [] for title_id in title_ids}\n",
    "\n",
    "# Generate recommendations for each title\n",
    "for title_id in title_ids:\n",
    "    recommendations = get_recommendations_for_title(weighted_content_recommender, title_id, top_k=10)\n",
    "    current_recommendations[title_id] = recommendations\n",
    "    print(f\"Current Recommendations for Title ID {title_id}:\")\n",
    "    print(recommendations)\n",
    "    print(\"\\n\")"
   ],
   "id": "68ef37236dd719d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Recommendations for Title ID tm107473:\n",
      "['tm54451', 'tm39130', 'tm33545', 'tm1138197', 'tm1278917', 'tm177922', 'tm160841', 'tm144685', 'tm1388422', 'tm111589']\n",
      "\n",
      "\n",
      "Current Recommendations for Title ID tm50355:\n",
      "['ts294208', 'tm350717', 'ts106126', 'tm136061', 'tm49065', 'tm181695', 'tm139775', 'tm1365333', 'tm1196434', 'ts26763']\n",
      "\n",
      "\n",
      "Current Recommendations for Title ID ts89259:\n",
      "['tm44430', 'ts271532', 'ts22246', 'ts302830', 'ts262357', 'ts20248', 'tm104832', 'ts4647', 'ts388033', 'ts37490']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Evaluating Recommendation Quality\n",
    "\n",
    "We'll compare the **ideal recommendations** with the **current recommendations** to assess how well our system is performing.\n",
    "\n",
    "For each title and each user associated with it:\n",
    "\n",
    "- **Ideal Recommendation:** The next title the user interacted with.\n",
    "- **Actual Recommendation:** The top-K titles recommended by the system.\n",
    "\n",
    "We'll calculate **Precision@K** for each user and then compute the **average Precision@K** across all users for each title.\n"
   ],
   "id": "22cc42f043bf22aa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T14:50:17.136765Z",
     "start_time": "2024-10-15T14:50:16.761881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize a dictionary to hold precision scores per title\n",
    "precision_scores_per_title = {title_id: [] for title_id in title_ids}\n",
    "\n",
    "# Define the value of K\n",
    "k = 5 \n",
    "\n",
    "for title_id in title_ids:\n",
    "    print(f\"Evaluating Recommendations for Title ID {title_id}:\")\n",
    "    ideal_recs = ideal_recommendations[title_id]\n",
    "    current_recs = current_recommendations[title_id]\n",
    "    \n",
    "    # Iterate over each user and their ideal recommendation\n",
    "    for user_id, ideal_rec in ideal_recs.items():\n",
    "        # Check if the ideal recommendation is in the top-K recommendations\n",
    "        if ideal_rec in current_recs[:k]:\n",
    "            precision_scores_per_title[title_id].append(1.0)  # Perfect precision for this user\n",
    "        else:\n",
    "            precision_scores_per_title[title_id].append(0.0)  # Missed recommendation\n",
    "    \n",
    "    # Calculate average Precision@K for the title\n",
    "    if precision_scores_per_title[title_id]:\n",
    "        average_precision = np.mean(precision_scores_per_title[title_id])\n",
    "    else:\n",
    "        average_precision = np.nan  # Handle cases with no evaluations\n",
    "    \n",
    "    print(f\"Average Precision@{k} for Title ID {title_id}: {average_precision}\\n\")\n"
   ],
   "id": "df2013b6b36668a0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Recommendations for Title ID tm107473:\n",
      "Average Precision@5 for Title ID tm107473: 0.0\n",
      "\n",
      "Evaluating Recommendations for Title ID tm50355:\n",
      "Average Precision@5 for Title ID tm50355: 0.0\n",
      "\n",
      "Evaluating Recommendations for Title ID ts89259:\n",
      "Average Precision@5 for Title ID ts89259: 0.0\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T17:57:15.142725Z",
     "start_time": "2024-10-15T17:57:15.126471Z"
    }
   },
   "cell_type": "code",
   "source": "len(ideal_recs)",
   "id": "45b775dfa0a8b82e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1161"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
